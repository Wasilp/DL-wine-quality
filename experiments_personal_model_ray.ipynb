{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-04 13:59:49,532\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.34',\n",
       " 'raylet_ip_address': '192.168.1.34',\n",
       " 'redis_address': '192.168.1.34:6379',\n",
       " 'object_store_address': 'tcp://127.0.0.1:65458',\n",
       " 'raylet_socket_name': 'tcp://127.0.0.1:65444',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': 'C:\\\\Users\\\\Pierre\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2021-03-04_13-59-49_151186_9108',\n",
       " 'metrics_export_port': 65501,\n",
       " 'node_id': 'd9ddbd9df73d2dffea0bd7b4d2111c7578d2cf15a01390807a2d2401'}"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.examples.mnist_pytorch import get_data_loaders, ConvNet, train, test\n",
    "from ray.tune import CLIReporter\n",
    "%matplotlib inline\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "filename = \"./data/wine.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "# drop col index\n",
    "df = df.drop(['index'],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(19852, 12)\n3    2836\n4    2836\n5    2836\n6    2836\n7    2836\n8    2836\n9    2836\nName: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Resample:\n",
    "df_majority = df[df['quality']== 6]\n",
    "for i in range(3,10):\n",
    "    majority_len = df[df['quality']== 6].shape[0]\n",
    "    if i != 6:\n",
    "        minority_len = df[df['quality'] == i].shape[0]\n",
    "\n",
    "        df_minority = df[df['quality'] == i]\n",
    "\n",
    "        df_majority_upsampled = resample(df_minority,replace=True,n_samples = majority_len,random_state=1)\n",
    "\n",
    "        df_majority = df_majority.append(df_majority_upsampled)\n",
    "        \n",
    "\n",
    "df = df_majority\n",
    "print(df.shape)\n",
    "print(df['quality'].value_counts())\n",
    "df = df.sample(frac=1).reset_index(drop=True) # Shuffle dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Creating a test/train split\n",
    "\n",
    "train_test_split_fraction = 0.80\n",
    "split_index = int(df.shape[0] * train_test_split_fraction)\n",
    "df_train = df[:split_index]\n",
    "df_test = df[split_index:]\n",
    "\n",
    "target = pd.get_dummies(df['quality']).values # One hot encode\n",
    "\n",
    "#target[:5]\n",
    "#target = df['quality'].to_numpy()\n",
    "#target = target.reshape(6497,1)\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15881, 11)\n(3971, 11)\n(15881, 7)\n(3971, 7)\n"
     ]
    }
   ],
   "source": [
    "# Selecting the features and the target\n",
    "X_train = df_train.drop('quality', axis = 1).values\n",
    "X_test = df_test.drop('quality', axis = 1).values\n",
    "\n",
    "y_train = target[:split_index]\n",
    "y_test = target[split_index:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e8e3d8ad2537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train.astype(np.float32)) \n",
    "y_train = torch.tensor(y_train.astype(np.float32))\n",
    "X_test = torch.tensor(X_test.astype(np.float32)) \n",
    "y_test = torch.tensor(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO DEFINE NEURONS,BATCH,EPOCHS,NB_LAYER,MODEL,LOSS FUNC\n",
    "#nb_hidden_neurons = 100\n",
    "nb_layer = 4 \n",
    "nb_features=X_train.shape[1]\n",
    "nb_classes = len(pd.unique(df['quality']))\n",
    "#activation_function = nn.SiLU()\n",
    "#last_layer_activation = nn.Softmax()\n",
    "layer_kind = nn.Linear\n",
    "#batch_size = 50\n",
    "#epochs = 75\n",
    "#criterion = nn.MSELoss()\n",
    "#learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self,nb_features,nb_classes,nb_layer,activation_function,last_layer_activation,layer_kind,nb_hidden_neurons):\n",
    "        \"\"\"Here we define the layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.activation_function = activation_function\n",
    "        self.last_layer_activation = last_layer_activation\n",
    "       \n",
    "        for i in range(1,nb_layer):\n",
    "            if i == 1 :\n",
    "                setattr(self, f\"layer_{i}\", layer_kind(nb_features,nb_hidden_neurons))\n",
    "            elif i == nb_layer-1:\n",
    "                setattr(self, f\"layer_{i}\", layer_kind(nb_hidden_neurons,nb_classes))\n",
    "            else:\n",
    "                setattr(self, f\"layer_{i}\", layer_kind(nb_hidden_neurons,nb_hidden_neurons))\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"Here we combine the layers\n",
    "        \"\"\"\n",
    "        for i in range(1,nb_layer):\n",
    "            if i == nb_layer-1:\n",
    "                x = self.last_layer_activation(getattr(self,f'layer_{i}')(x))\n",
    "            else:\n",
    "                x = self.activation_function(getattr(self,f'layer_{i}')(x))\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_nn = Network(nb_features,nb_classes,nb_layer,activation_function,last_layer_activation,layer_kind)\n",
    "#my_nn\n",
    "#optimizer = torch.optim.Adam(my_nn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(config):\n",
    "    \"\"\" Train the neural network, feeding it `batch_size` at a time\n",
    "    and saving statistics every `nb_steps_loss_sum` steps.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    - batch_size [int] : the number of input samples at each training step (called a batch)\n",
    "    - nb_steps_loss_sum [int] : the number of batches before saving the loss for plotting\n",
    "    \n",
    "    Returns:\n",
    "    - loss_list : [List[double]] : value of the loss every `nb_steps_loss_sum` steps\n",
    "    \"\"\"\n",
    "\n",
    "    nb_steps_loss_sum = 10 \n",
    "    #optimizer = config[\"optimizer\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    epochs = config[\"epoch\"]\n",
    "    nb_layer = 4 \n",
    "    activation_function=config[\"activation_function\"]\n",
    "    last_layer_activation=config[\"last_layer_activation\"]\n",
    "    nb_hidden_neurons=config[\"nb_hidden_neurons\"]\n",
    "   \n",
    "    my_nn = Network(nb_features,nb_classes,\n",
    "                    nb_layer,\n",
    "                    activation_function,\n",
    "                    last_layer_activation,\n",
    "                    layer_kind,\n",
    "                    nb_hidden_neurons)\n",
    "    my_nn\n",
    "     \n",
    "    optimizer = torch.optim.AdamW(my_nn.parameters(), lr=config[\"lr\"])\n",
    "    loss_list = []\n",
    "    running_loss = 0\n",
    "    batch_nb = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs): # Number of times to iterate through the complete dataset\n",
    "        for idx in range(0, X_train.shape[0], batch_size):\n",
    "            \n",
    "            # Get input and output\n",
    "            input_batch = X_train[idx:idx + batch_size]\n",
    "            target = y_train[idx:idx + batch_size]\n",
    "            \n",
    "            # TO COMPLETE:\n",
    "            # - zero gradient buffers\n",
    "            optimizer.zero_grad()\n",
    "            # - compute the forward pass\n",
    "            output = my_nn(input_batch.float())\n",
    "            # - compute the loss\n",
    "            loss = config[\"criterion\"](output, target.float())\n",
    "            # - backpropagate\n",
    "            loss.backward()\n",
    "            # - do a step\n",
    "            optimizer.step()\n",
    "          \n",
    "            \n",
    "            # Save the loss every `running_loss_steps` batches\n",
    "            running_loss += loss.item()\n",
    "            save_loss_condition = batch_nb % nb_steps_loss_sum == (nb_steps_loss_sum - 1)\n",
    "            if save_loss_condition:    \n",
    "                loss_list.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "            batch_nb+= 1\n",
    "        \n",
    "        tune.report(loss=abs(loss_list[len(loss_list)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 398.097708 277.314375\" width=\"398.097708pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-03-03T16:00:24.503534</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 277.314375 \r\nL 398.097708 277.314375 \r\nL 398.097708 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\nL 43.78125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mc5b759cdf0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(55.818182 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"122.834087\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 500 -->\r\n      <g transform=\"translate(113.290337 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.668742\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 1000 -->\r\n      <g transform=\"translate(173.943742 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.503398\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 1500 -->\r\n      <g transform=\"translate(237.778398 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.338053\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 2000 -->\r\n      <g transform=\"translate(301.613053 254.356562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.172708\" xlink:href=\"#mc5b759cdf0\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 2500 -->\r\n      <g transform=\"translate(365.447708 254.356562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Batches/10 -->\r\n     <g transform=\"translate(183.080469 268.034687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 19.671875 34.8125 \r\nL 19.671875 8.109375 \r\nL 35.5 8.109375 \r\nQ 43.453125 8.109375 47.28125 11.40625 \r\nQ 51.125 14.703125 51.125 21.484375 \r\nQ 51.125 28.328125 47.28125 31.5625 \r\nQ 43.453125 34.8125 35.5 34.8125 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 42.828125 \r\nL 34.28125 42.828125 \r\nQ 41.5 42.828125 45.03125 45.53125 \r\nQ 48.578125 48.25 48.578125 53.8125 \r\nQ 48.578125 59.328125 45.03125 62.0625 \r\nQ 41.5 64.796875 34.28125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 35.015625 72.90625 \r\nQ 46.296875 72.90625 52.390625 68.21875 \r\nQ 58.5 63.53125 58.5 54.890625 \r\nQ 58.5 48.1875 55.375 44.234375 \r\nQ 52.25 40.28125 46.1875 39.3125 \r\nQ 53.46875 37.75 57.5 32.78125 \r\nQ 61.53125 27.828125 61.53125 20.40625 \r\nQ 61.53125 10.640625 54.890625 5.3125 \r\nQ 48.25 0 35.984375 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-66\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path d=\"M 25.390625 72.90625 \r\nL 33.6875 72.90625 \r\nL 8.296875 -9.28125 \r\nL 0 -9.28125 \r\nz\r\n\" id=\"DejaVuSans-47\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-66\"/>\r\n      <use x=\"68.603516\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"129.882812\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"169.091797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"224.072266\" xlink:href=\"#DejaVuSans-104\"/>\r\n      <use x=\"287.451172\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"348.974609\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"401.074219\" xlink:href=\"#DejaVuSans-47\"/>\r\n      <use x=\"434.765625\" xlink:href=\"#DejaVuSans-49\"/>\r\n      <use x=\"498.388672\" xlink:href=\"#DejaVuSans-48\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"me4204b72b4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"230.284665\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(20.878125 234.083884)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"200.697228\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(20.878125 204.496447)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"171.109791\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(20.878125 174.90901)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"141.522354\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(20.878125 145.321573)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"111.934917\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.2 -->\r\n      <g transform=\"translate(20.878125 115.734135)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"82.34748\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.4 -->\r\n      <g transform=\"translate(20.878125 86.146698)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"52.760043\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.6 -->\r\n      <g transform=\"translate(20.878125 56.559261)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#me4204b72b4\" y=\"23.172606\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 1.8 -->\r\n      <g transform=\"translate(20.878125 26.971824)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_16\">\r\n     <!-- Loss -->\r\n     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p873a848bd2)\" d=\"M 58.999432 32.201761 \r\nL 59.25477 95.568207 \r\nL 59.637778 114.035786 \r\nL 59.893117 116.641391 \r\nL 60.020786 115.855267 \r\nL 60.148456 120.873217 \r\nL 60.276125 116.062198 \r\nL 60.403794 115.820842 \r\nL 60.531464 124.683482 \r\nL 60.659133 117.775959 \r\nL 60.786802 117.952804 \r\nL 61.16981 124.014318 \r\nL 61.297479 120.831016 \r\nL 61.552818 128.762605 \r\nL 61.808157 122.929196 \r\nL 61.935826 128.122934 \r\nL 62.063495 118.038824 \r\nL 62.191165 124.690918 \r\nL 62.318834 118.221999 \r\nL 62.446503 131.25801 \r\nL 62.574173 124.392257 \r\nL 62.701842 129.242436 \r\nL 62.95718 119.890898 \r\nL 63.08485 129.957295 \r\nL 63.212519 128.532945 \r\nL 63.340188 128.513851 \r\nL 63.467858 128.156248 \r\nL 63.595527 134.660935 \r\nL 63.723196 128.390096 \r\nL 63.850866 134.597756 \r\nL 64.106204 129.689529 \r\nL 64.233874 135.960061 \r\nL 64.361543 135.415254 \r\nL 64.489212 131.754625 \r\nL 64.616881 142.335309 \r\nL 64.744551 130.703226 \r\nL 64.87222 139.99056 \r\nL 64.999889 135.552237 \r\nL 65.127559 136.68008 \r\nL 65.255228 136.453442 \r\nL 65.382897 130.402886 \r\nL 65.510567 136.24457 \r\nL 65.638236 134.697095 \r\nL 65.765905 136.868211 \r\nL 65.893575 123.896988 \r\nL 66.021244 125.279045 \r\nL 66.276583 135.043077 \r\nL 66.404252 132.468774 \r\nL 66.65959 140.450222 \r\nL 66.78726 130.151653 \r\nL 66.914929 136.330273 \r\nL 67.042598 134.900301 \r\nL 67.170268 141.45849 \r\nL 67.297937 136.738988 \r\nL 67.425606 145.262266 \r\nL 67.553276 139.654962 \r\nL 67.680945 142.2039 \r\nL 67.808614 141.57751 \r\nL 67.936284 144.818305 \r\nL 68.063953 142.964821 \r\nL 68.191622 144.310346 \r\nL 68.319291 141.092676 \r\nL 68.446961 148.994853 \r\nL 68.57463 146.334129 \r\nL 68.702299 150.752759 \r\nL 68.829969 142.040353 \r\nL 68.957638 155.70201 \r\nL 69.085307 139.838292 \r\nL 69.212977 148.196797 \r\nL 69.340646 145.134095 \r\nL 69.468315 146.435833 \r\nL 69.595985 145.693813 \r\nL 69.723654 147.802233 \r\nL 69.851323 141.975844 \r\nL 69.978993 142.268946 \r\nL 70.234331 139.356767 \r\nL 70.362 140.745577 \r\nL 70.617339 145.833772 \r\nL 70.745008 145.093952 \r\nL 70.872678 142.694379 \r\nL 71.000347 148.135056 \r\nL 71.128016 143.837441 \r\nL 71.255686 144.135988 \r\nL 71.383355 142.830144 \r\nL 71.511024 149.470003 \r\nL 71.638694 147.877698 \r\nL 71.894032 149.228713 \r\nL 72.021701 148.44875 \r\nL 72.149371 150.643191 \r\nL 72.27704 149.652958 \r\nL 72.532379 153.224533 \r\nL 72.660048 153.54484 \r\nL 72.915387 151.581125 \r\nL 73.043056 156.617915 \r\nL 73.170725 149.549485 \r\nL 73.298395 152.370329 \r\nL 73.426064 149.714727 \r\nL 73.553733 155.805113 \r\nL 73.681403 148.776612 \r\nL 73.809072 153.667178 \r\nL 73.936741 146.197483 \r\nL 74.06441 150.901354 \r\nL 74.19208 144.341969 \r\nL 74.319749 146.852813 \r\nL 74.447418 142.448281 \r\nL 74.575088 156.95384 \r\nL 74.702757 149.649929 \r\nL 75.085765 152.049965 \r\nL 75.213434 149.422783 \r\nL 75.341104 152.733969 \r\nL 75.468773 147.910325 \r\nL 75.596442 153.429699 \r\nL 75.851781 154.803285 \r\nL 75.97945 157.943061 \r\nL 76.107119 155.600048 \r\nL 76.234789 156.818352 \r\nL 76.362458 154.645086 \r\nL 76.490127 160.169586 \r\nL 76.617797 153.120934 \r\nL 76.745466 162.021675 \r\nL 77.000805 157.593377 \r\nL 77.128474 158.414966 \r\nL 77.256143 156.112376 \r\nL 77.383813 157.120088 \r\nL 77.511482 153.112583 \r\nL 77.639151 160.101827 \r\nL 77.89449 152.480418 \r\nL 78.022159 153.23845 \r\nL 78.149828 152.564191 \r\nL 78.277498 147.482564 \r\nL 78.405167 154.978162 \r\nL 78.532836 145.581854 \r\nL 78.660506 163.216751 \r\nL 78.788175 152.737285 \r\nL 78.915844 163.726548 \r\nL 79.171183 151.070317 \r\nL 79.426522 155.586138 \r\nL 79.554191 157.873749 \r\nL 79.68186 156.322193 \r\nL 79.809529 158.041898 \r\nL 79.937199 157.986126 \r\nL 80.192537 164.041166 \r\nL 80.320207 157.249316 \r\nL 80.575545 166.124098 \r\nL 80.703215 158.763615 \r\nL 80.830884 167.665486 \r\nL 80.958553 158.774127 \r\nL 81.086223 164.872503 \r\nL 81.341561 159.491034 \r\nL 81.46923 162.302828 \r\nL 81.5969 160.095602 \r\nL 81.724569 160.560099 \r\nL 81.852238 161.629914 \r\nL 81.979908 155.00534 \r\nL 82.107577 154.696845 \r\nL 82.235246 159.770849 \r\nL 82.362916 151.835284 \r\nL 82.490585 161.777917 \r\nL 82.618254 153.77307 \r\nL 82.745924 166.157235 \r\nL 82.873593 156.953193 \r\nL 83.001262 168.933104 \r\nL 83.256601 156.242929 \r\nL 83.38427 158.17103 \r\nL 83.511939 158.919905 \r\nL 83.639609 165.118183 \r\nL 83.767278 160.198117 \r\nL 83.894947 164.65412 \r\nL 84.022617 158.081411 \r\nL 84.150286 168.526481 \r\nL 84.405625 161.774055 \r\nL 84.533294 163.75182 \r\nL 84.660963 171.750821 \r\nL 84.788633 161.98261 \r\nL 84.916302 171.622056 \r\nL 85.043971 160.425031 \r\nL 85.17164 170.672809 \r\nL 85.29931 161.859156 \r\nL 85.426979 168.342753 \r\nL 85.809987 161.382567 \r\nL 85.937656 163.84604 \r\nL 86.065326 161.447012 \r\nL 86.192995 156.561052 \r\nL 86.320664 163.831165 \r\nL 86.576003 159.918468 \r\nL 86.703672 162.607138 \r\nL 86.831342 162.911154 \r\nL 86.959011 169.99568 \r\nL 87.08668 162.904629 \r\nL 87.214349 164.869734 \r\nL 87.342019 160.630539 \r\nL 87.469688 160.691341 \r\nL 87.597357 160.891202 \r\nL 87.725027 172.227934 \r\nL 87.852696 161.56673 \r\nL 87.980365 165.978066 \r\nL 88.108035 165.156026 \r\nL 88.235704 172.225833 \r\nL 88.491043 165.431135 \r\nL 88.618712 166.457978 \r\nL 88.746381 173.521557 \r\nL 88.87405 165.554491 \r\nL 89.00172 171.260153 \r\nL 89.129389 163.823431 \r\nL 89.257058 174.469403 \r\nL 89.384728 165.325342 \r\nL 89.512397 168.254426 \r\nL 89.640066 165.91423 \r\nL 89.767736 167.135185 \r\nL 89.895405 162.854077 \r\nL 90.023074 165.429717 \r\nL 90.278413 163.794961 \r\nL 90.406082 163.256175 \r\nL 90.533752 163.414299 \r\nL 90.661421 158.758116 \r\nL 90.78909 167.991381 \r\nL 90.916759 168.999751 \r\nL 91.044429 165.967855 \r\nL 91.172098 166.943562 \r\nL 91.299767 169.757305 \r\nL 91.427437 162.028515 \r\nL 91.682775 167.414027 \r\nL 91.810445 172.251314 \r\nL 91.938114 169.076153 \r\nL 92.065783 169.227051 \r\nL 92.321122 167.950108 \r\nL 92.448791 168.717653 \r\nL 92.57646 167.843483 \r\nL 92.831799 173.379143 \r\nL 92.959468 168.221373 \r\nL 93.087138 170.417303 \r\nL 93.214807 169.383935 \r\nL 93.342476 172.076068 \r\nL 93.470146 167.952379 \r\nL 93.597815 168.643029 \r\nL 93.725484 164.850107 \r\nL 93.853154 170.641557 \r\nL 93.980823 163.332911 \r\nL 94.108492 166.395382 \r\nL 94.236162 165.119407 \r\nL 94.363831 169.08546 \r\nL 94.4915 166.399605 \r\nL 94.619169 167.358203 \r\nL 94.746839 159.121041 \r\nL 94.874508 177.62441 \r\nL 95.002177 166.962624 \r\nL 95.257516 171.65229 \r\nL 95.512855 163.936751 \r\nL 95.895863 172.711359 \r\nL 96.023532 170.479438 \r\nL 96.151201 171.385296 \r\nL 96.278871 173.456201 \r\nL 96.40654 170.68887 \r\nL 96.534209 171.238049 \r\nL 96.661878 170.339053 \r\nL 96.789548 176.867356 \r\nL 96.917217 170.151131 \r\nL 97.044886 173.086732 \r\nL 97.172556 172.922023 \r\nL 97.300225 173.375808 \r\nL 97.427894 173.18831 \r\nL 97.555564 174.380647 \r\nL 97.810902 165.325021 \r\nL 97.938572 171.642935 \r\nL 98.19391 165.471509 \r\nL 98.321579 169.946492 \r\nL 98.449249 167.501878 \r\nL 98.576918 168.020703 \r\nL 98.704587 170.466383 \r\nL 98.832257 162.085452 \r\nL 98.959926 179.662258 \r\nL 99.087595 166.683274 \r\nL 99.215265 179.436542 \r\nL 99.470603 167.533759 \r\nL 99.853611 177.627698 \r\nL 99.981281 172.13221 \r\nL 100.10895 171.878056 \r\nL 100.491958 177.110797 \r\nL 100.619627 168.483845 \r\nL 100.874966 180.893249 \r\nL 101.002635 171.457873 \r\nL 101.130304 177.319101 \r\nL 101.257974 173.582938 \r\nL 101.385643 177.097931 \r\nL 101.513312 173.902956 \r\nL 101.640982 174.936777 \r\nL 101.89632 168.518421 \r\nL 102.151659 171.420392 \r\nL 102.406997 167.338134 \r\nL 102.534667 171.827959 \r\nL 102.662336 167.631356 \r\nL 102.790005 171.972756 \r\nL 102.917675 168.376665 \r\nL 103.045344 181.870386 \r\nL 103.173013 167.140054 \r\nL 103.300683 183.084889 \r\nL 103.556021 170.461557 \r\nL 103.683691 170.60535 \r\nL 103.939029 179.862727 \r\nL 104.066698 174.918352 \r\nL 104.194368 175.63634 \r\nL 104.322037 172.667006 \r\nL 104.449706 181.822003 \r\nL 104.705045 172.375734 \r\nL 104.832714 176.435729 \r\nL 104.960384 184.153492 \r\nL 105.088053 172.817755 \r\nL 105.215722 180.152252 \r\nL 105.343392 173.758704 \r\nL 105.471061 180.961 \r\nL 105.59873 169.751818 \r\nL 105.726399 181.245188 \r\nL 105.981738 170.208541 \r\nL 106.109407 169.533467 \r\nL 106.364746 174.685026 \r\nL 106.492415 169.610817 \r\nL 106.620085 175.702316 \r\nL 106.747754 174.736624 \r\nL 106.875423 170.66144 \r\nL 107.003093 175.514244 \r\nL 107.130762 175.908142 \r\nL 107.258431 179.331484 \r\nL 107.386101 176.239601 \r\nL 107.51377 177.541375 \r\nL 107.641439 174.267034 \r\nL 107.896778 175.641178 \r\nL 108.024447 185.923811 \r\nL 108.152116 173.686842 \r\nL 108.279786 174.069302 \r\nL 108.535124 183.141189 \r\nL 108.790463 175.512109 \r\nL 108.918132 178.287656 \r\nL 109.045802 186.578482 \r\nL 109.173471 174.228554 \r\nL 109.30114 180.689724 \r\nL 109.428809 174.766969 \r\nL 109.556479 182.180771 \r\nL 109.684148 173.73487 \r\nL 109.811817 176.478468 \r\nL 109.939487 174.245716 \r\nL 110.067156 174.372371 \r\nL 110.194825 169.513737 \r\nL 110.322495 178.465029 \r\nL 110.450164 176.391843 \r\nL 110.577833 176.375199 \r\nL 110.705503 175.46902 \r\nL 110.833172 176.045633 \r\nL 110.960841 168.307162 \r\nL 111.088511 180.678635 \r\nL 111.21618 180.832985 \r\nL 111.343849 175.98178 \r\nL 111.599188 181.251394 \r\nL 111.726857 175.718018 \r\nL 111.854526 175.286207 \r\nL 112.109865 183.656885 \r\nL 112.365204 176.08275 \r\nL 112.492873 181.283658 \r\nL 112.748212 180.784004 \r\nL 112.875881 179.444607 \r\nL 113.00355 184.836375 \r\nL 113.131219 184.285967 \r\nL 113.258889 176.510374 \r\nL 113.386558 179.39462 \r\nL 113.514227 179.130638 \r\nL 113.641897 178.138275 \r\nL 113.769566 180.516854 \r\nL 114.024905 171.308271 \r\nL 114.152574 177.477092 \r\nL 114.280243 171.338565 \r\nL 114.535582 177.704805 \r\nL 114.663251 178.373272 \r\nL 114.790921 178.170992 \r\nL 114.91859 176.108611 \r\nL 115.046259 169.201791 \r\nL 115.173928 188.295957 \r\nL 115.301598 177.792255 \r\nL 115.429267 179.634532 \r\nL 115.556936 183.621732 \r\nL 115.812275 177.319651 \r\nL 115.939944 177.819084 \r\nL 116.195283 184.131777 \r\nL 116.322952 178.023552 \r\nL 116.450622 178.39265 \r\nL 116.578291 185.504501 \r\nL 116.70596 179.073507 \r\nL 116.833629 183.617474 \r\nL 116.961299 180.173108 \r\nL 117.088968 186.813981 \r\nL 117.216637 181.693961 \r\nL 117.471976 180.22183 \r\nL 117.599645 183.483371 \r\nL 117.727315 181.32124 \r\nL 117.854984 183.111605 \r\nL 118.110323 171.787744 \r\nL 118.237992 178.629627 \r\nL 118.493331 174.361128 \r\nL 118.621 180.222593 \r\nL 118.748669 176.871417 \r\nL 119.004008 178.595392 \r\nL 119.131677 172.97462 \r\nL 119.259346 188.90332 \r\nL 119.387016 175.839383 \r\nL 119.514685 188.953187 \r\nL 119.770024 177.516098 \r\nL 119.897693 177.700722 \r\nL 120.025362 179.253066 \r\nL 120.153032 186.737466 \r\nL 120.40837 177.616028 \r\nL 120.53604 182.02033 \r\nL 120.663709 182.321653 \r\nL 120.791378 186.223442 \r\nL 120.919047 181.255282 \r\nL 121.174386 189.151984 \r\nL 121.302055 180.950942 \r\nL 121.429725 184.206009 \r\nL 121.557394 179.632635 \r\nL 121.685063 183.790892 \r\nL 121.812733 181.422067 \r\nL 121.940402 182.416184 \r\nL 122.195741 174.996985 \r\nL 122.451079 179.138567 \r\nL 122.578748 177.204667 \r\nL 122.706418 177.590495 \r\nL 122.834087 181.710409 \r\nL 122.961756 176.04201 \r\nL 123.089426 181.57203 \r\nL 123.217095 175.994152 \r\nL 123.344764 189.830137 \r\nL 123.472434 175.1126 \r\nL 123.600103 193.472762 \r\nL 123.855442 177.702204 \r\nL 124.11078 179.493087 \r\nL 124.23845 188.87471 \r\nL 124.366119 181.429953 \r\nL 124.493788 181.585877 \r\nL 124.621457 180.919903 \r\nL 124.749127 188.432426 \r\nL 124.876796 183.392477 \r\nL 125.004465 185.482703 \r\nL 125.132135 185.459672 \r\nL 125.259804 191.155674 \r\nL 125.387473 180.574214 \r\nL 125.515143 186.536957 \r\nL 125.642812 178.281746 \r\nL 125.770481 188.510581 \r\nL 125.898151 178.896474 \r\nL 126.02582 189.583435 \r\nL 126.153489 178.859551 \r\nL 126.408828 176.353597 \r\nL 126.536497 182.3573 \r\nL 126.791836 178.67741 \r\nL 126.919505 182.731119 \r\nL 127.174844 179.282221 \r\nL 127.557852 187.67477 \r\nL 127.685521 187.680924 \r\nL 127.94086 180.644479 \r\nL 128.068529 183.262531 \r\nL 128.196198 179.87652 \r\nL 128.323867 193.485097 \r\nL 128.451537 178.019903 \r\nL 128.706875 184.51324 \r\nL 128.834545 190.080383 \r\nL 129.089883 185.527308 \r\nL 129.217553 187.231226 \r\nL 129.345222 192.563988 \r\nL 129.472891 181.594209 \r\nL 129.600561 185.416333 \r\nL 129.72823 178.636498 \r\nL 129.855899 190.775979 \r\nL 129.983568 181.975894 \r\nL 130.111238 187.722573 \r\nL 130.238907 179.849717 \r\nL 130.366576 181.343151 \r\nL 130.494246 179.027643 \r\nL 130.621915 184.830489 \r\nL 130.749584 180.326162 \r\nL 130.877254 184.602816 \r\nL 131.004923 183.233796 \r\nL 131.132592 184.992088 \r\nL 131.260262 177.920461 \r\nL 131.387931 189.009908 \r\nL 131.5156 187.937453 \r\nL 131.64327 182.339253 \r\nL 131.770939 190.079037 \r\nL 131.898608 187.570475 \r\nL 132.026277 182.343833 \r\nL 132.153947 182.265939 \r\nL 132.409285 189.050066 \r\nL 132.664624 182.56337 \r\nL 132.919963 188.624144 \r\nL 133.047632 189.719589 \r\nL 133.175301 187.756603 \r\nL 133.302971 192.858438 \r\nL 133.43064 189.758726 \r\nL 133.558309 183.632169 \r\nL 133.685978 183.540512 \r\nL 133.941317 185.10818 \r\nL 134.068986 188.365263 \r\nL 134.196656 186.909722 \r\nL 134.324325 179.982936 \r\nL 134.451994 186.1984 \r\nL 134.579664 181.372624 \r\nL 135.090341 188.125894 \r\nL 135.34568 177.518542 \r\nL 135.473349 196.96194 \r\nL 135.601018 185.960513 \r\nL 135.728687 185.577566 \r\nL 135.856357 191.853201 \r\nL 135.984026 185.238031 \r\nL 136.111695 185.802915 \r\nL 136.239365 184.17726 \r\nL 136.494703 188.917103 \r\nL 136.622373 182.523535 \r\nL 137.13305 192.621644 \r\nL 137.260719 188.428386 \r\nL 137.388388 193.293137 \r\nL 137.771396 183.836024 \r\nL 137.899066 189.114428 \r\nL 138.026735 187.002409 \r\nL 138.154404 191.98989 \r\nL 138.409743 181.543397 \r\nL 138.537412 188.070134 \r\nL 138.665082 186.986975 \r\nL 138.792751 181.581721 \r\nL 138.92042 187.65772 \r\nL 139.04809 185.281543 \r\nL 139.175759 187.690469 \r\nL 139.303428 186.146128 \r\nL 139.431097 180.952403 \r\nL 139.558767 198.006278 \r\nL 139.686436 183.826303 \r\nL 139.814105 195.081273 \r\nL 140.069444 184.784009 \r\nL 140.197113 186.688196 \r\nL 140.324783 184.899314 \r\nL 140.452452 193.622488 \r\nL 140.707791 181.555253 \r\nL 140.83546 188.683767 \r\nL 140.963129 185.991818 \r\nL 141.090799 194.282075 \r\nL 141.218468 188.293369 \r\nL 141.473806 196.009455 \r\nL 141.601476 187.504612 \r\nL 141.729145 187.537516 \r\nL 141.856814 184.803672 \r\nL 141.984484 188.200407 \r\nL 142.112153 187.906763 \r\nL 142.239822 190.240397 \r\nL 142.495161 184.238953 \r\nL 142.62283 188.4849 \r\nL 142.7505 188.280064 \r\nL 142.878169 183.668599 \r\nL 143.005838 184.760181 \r\nL 143.133507 189.852479 \r\nL 143.261177 184.034999 \r\nL 143.388846 189.508087 \r\nL 143.516515 185.258706 \r\nL 143.644185 198.067323 \r\nL 143.771854 182.481384 \r\nL 143.899523 200.143915 \r\nL 144.154862 185.171846 \r\nL 144.282531 186.932651 \r\nL 144.410201 185.19805 \r\nL 144.53787 195.544669 \r\nL 144.665539 185.172565 \r\nL 144.793209 187.091781 \r\nL 144.920878 186.445764 \r\nL 145.048547 192.297558 \r\nL 145.176216 190.345078 \r\nL 145.431555 192.339849 \r\nL 145.559224 197.893424 \r\nL 145.686894 185.809479 \r\nL 145.814563 189.802773 \r\nL 145.942232 184.366699 \r\nL 146.069902 192.413629 \r\nL 146.197571 184.391717 \r\nL 146.32524 196.301927 \r\nL 146.45291 187.213529 \r\nL 146.580579 186.798693 \r\nL 146.708248 184.136879 \r\nL 146.835917 191.7069 \r\nL 147.091256 185.948839 \r\nL 147.218925 189.011751 \r\nL 147.346595 188.442464 \r\nL 147.474264 185.434241 \r\nL 147.601933 190.970265 \r\nL 147.729603 190.526104 \r\nL 147.857272 194.350413 \r\nL 147.984941 193.231932 \r\nL 148.24028 186.740441 \r\nL 148.367949 189.933864 \r\nL 148.495619 186.899392 \r\nL 148.623288 198.849323 \r\nL 148.750957 181.721582 \r\nL 149.133965 195.640252 \r\nL 149.389304 192.048834 \r\nL 149.516973 192.993549 \r\nL 149.644642 198.819535 \r\nL 149.772312 186.183647 \r\nL 149.899981 188.094061 \r\nL 150.02765 183.273976 \r\nL 150.15532 192.64284 \r\nL 150.282989 186.315933 \r\nL 150.410658 194.767261 \r\nL 150.538327 186.173817 \r\nL 150.665997 188.419961 \r\nL 150.793666 183.95396 \r\nL 150.921335 188.745632 \r\nL 151.049005 186.218621 \r\nL 151.176674 188.810828 \r\nL 151.304343 189.098158 \r\nL 151.432013 189.84868 \r\nL 151.559682 183.804059 \r\nL 151.687351 196.407458 \r\nL 151.815021 193.799763 \r\nL 151.94269 187.93401 \r\nL 152.070359 194.126911 \r\nL 152.325698 188.74748 \r\nL 152.453367 188.9667 \r\nL 152.581036 189.121821 \r\nL 152.708706 193.689672 \r\nL 152.836375 188.370902 \r\nL 152.964044 188.400024 \r\nL 153.091714 190.471001 \r\nL 153.219383 194.882318 \r\nL 153.347052 195.376901 \r\nL 153.474722 192.941531 \r\nL 153.602391 198.933874 \r\nL 153.985399 185.934445 \r\nL 154.113068 188.142441 \r\nL 154.240737 187.048575 \r\nL 154.368407 194.018096 \r\nL 154.496076 193.225405 \r\nL 154.623745 185.902987 \r\nL 154.751415 192.272749 \r\nL 154.879084 186.250291 \r\nL 155.006753 189.035155 \r\nL 155.134423 188.739826 \r\nL 155.389761 193.964943 \r\nL 155.6451 183.432486 \r\nL 155.772769 202.461412 \r\nL 156.028108 189.552551 \r\nL 156.155777 195.758135 \r\nL 156.283446 189.965102 \r\nL 156.411116 191.214554 \r\nL 156.538785 188.542226 \r\nL 156.794124 194.176568 \r\nL 156.921793 187.413944 \r\nL 157.177132 194.534914 \r\nL 157.304801 193.529292 \r\nL 157.43247 199.25607 \r\nL 157.56014 192.31386 \r\nL 157.687809 198.997869 \r\nL 158.070817 186.345223 \r\nL 158.198486 189.435839 \r\nL 158.326155 188.511217 \r\nL 158.453825 197.268248 \r\nL 158.709163 187.140983 \r\nL 158.836833 193.252871 \r\nL 158.964502 191.350701 \r\nL 159.092171 185.364195 \r\nL 159.219841 191.816061 \r\nL 159.34751 189.762873 \r\nL 159.475179 192.051902 \r\nL 159.602849 190.310749 \r\nL 159.730518 186.89919 \r\nL 159.858187 201.952214 \r\nL 159.985856 188.125099 \r\nL 160.113526 198.335961 \r\nL 160.368864 189.14699 \r\nL 160.496534 191.859191 \r\nL 160.624203 189.565559 \r\nL 160.751872 197.081775 \r\nL 161.007211 187.703037 \r\nL 161.13488 193.585804 \r\nL 161.26255 193.637973 \r\nL 161.390219 199.459111 \r\nL 161.517888 194.066525 \r\nL 161.645558 196.077211 \r\nL 161.773227 201.586575 \r\nL 162.028565 189.1532 \r\nL 162.156235 187.96679 \r\nL 162.539243 195.708219 \r\nL 162.794581 190.993011 \r\nL 162.922251 192.539507 \r\nL 163.04992 192.660238 \r\nL 163.177589 188.183406 \r\nL 163.305259 187.696658 \r\nL 163.432928 195.511464 \r\nL 163.560597 187.474939 \r\nL 163.688266 194.649942 \r\nL 163.815936 189.500189 \r\nL 163.943605 202.387311 \r\nL 164.071274 186.323009 \r\nL 164.198944 202.84546 \r\nL 164.454282 189.286767 \r\nL 164.581952 190.363297 \r\nL 164.709621 189.84882 \r\nL 164.83729 198.69309 \r\nL 164.96496 189.675717 \r\nL 165.092629 194.827926 \r\nL 165.220298 190.868792 \r\nL 165.347968 199.781178 \r\nL 165.475637 195.636807 \r\nL 165.603306 196.232788 \r\nL 165.730975 195.815701 \r\nL 165.858645 203.226273 \r\nL 165.986314 189.781824 \r\nL 166.113983 191.779334 \r\nL 166.241653 187.531495 \r\nL 166.369322 193.719027 \r\nL 166.496991 188.242296 \r\nL 166.624661 200.130305 \r\nL 166.879999 191.768331 \r\nL 167.007669 187.732538 \r\nL 167.135338 194.707928 \r\nL 167.390676 189.580822 \r\nL 167.518346 192.981669 \r\nL 167.646015 193.222771 \r\nL 167.773684 190.370535 \r\nL 167.901354 194.411058 \r\nL 168.029023 194.832794 \r\nL 168.156692 198.243233 \r\nL 168.412031 194.338622 \r\nL 168.5397 190.373861 \r\nL 168.66737 192.819436 \r\nL 168.795039 192.183442 \r\nL 168.922708 200.912833 \r\nL 169.050378 186.667259 \r\nL 169.178047 194.594274 \r\nL 169.305716 194.225367 \r\nL 169.433385 201.252282 \r\nL 169.688724 195.303168 \r\nL 169.816393 197.201378 \r\nL 169.944063 205.015721 \r\nL 170.071732 189.006459 \r\nL 170.199401 190.744018 \r\nL 170.327071 187.711592 \r\nL 170.45474 195.568952 \r\nL 170.582409 192.51904 \r\nL 170.710079 199.558466 \r\nL 170.837748 192.680918 \r\nL 170.965417 194.190625 \r\nL 171.093086 189.448538 \r\nL 171.220756 193.877554 \r\nL 171.348425 192.712579 \r\nL 171.603764 193.860721 \r\nL 171.731433 194.763634 \r\nL 171.859102 187.721274 \r\nL 171.986772 199.571989 \r\nL 172.114441 198.574188 \r\nL 172.24211 191.97238 \r\nL 172.36978 198.616741 \r\nL 172.497449 197.490873 \r\nL 172.625118 192.680957 \r\nL 172.752788 192.624664 \r\nL 172.880457 193.192754 \r\nL 173.008126 196.002831 \r\nL 173.135795 194.082535 \r\nL 173.263465 194.731806 \r\nL 173.391134 196.07733 \r\nL 173.518803 199.626641 \r\nL 173.774142 197.086967 \r\nL 173.901811 203.368801 \r\nL 174.029481 199.783572 \r\nL 174.15715 191.068836 \r\nL 174.284819 190.001035 \r\nL 174.412489 192.192217 \r\nL 174.540158 189.52144 \r\nL 174.667827 199.629478 \r\nL 174.795496 198.180442 \r\nL 174.923166 191.934463 \r\nL 175.050835 196.590448 \r\nL 175.178504 190.195664 \r\nL 175.306174 192.782638 \r\nL 175.433843 193.032882 \r\nL 175.689182 197.601116 \r\nL 175.94452 186.976045 \r\nL 176.07219 205.202259 \r\nL 176.327528 192.727059 \r\nL 176.455198 201.052618 \r\nL 176.582867 194.196116 \r\nL 176.710536 195.377461 \r\nL 176.838205 192.164832 \r\nL 176.965875 193.544528 \r\nL 177.093544 197.581344 \r\nL 177.221213 193.40921 \r\nL 177.476552 200.205047 \r\nL 177.604221 197.574603 \r\nL 177.731891 202.459511 \r\nL 177.85956 196.715079 \r\nL 177.987229 203.064011 \r\nL 178.370237 190.469802 \r\nL 178.497906 193.721561 \r\nL 178.625576 192.211887 \r\nL 178.753245 202.59733 \r\nL 179.008584 191.411357 \r\nL 179.136253 197.192628 \r\nL 179.263922 194.418465 \r\nL 179.391592 189.108801 \r\nL 179.519261 195.484612 \r\nL 179.64693 193.601461 \r\nL 179.902269 195.942914 \r\nL 180.029938 189.049855 \r\nL 180.157608 205.514822 \r\nL 180.285277 193.496539 \r\nL 180.412946 200.979204 \r\nL 180.668285 192.89313 \r\nL 180.795954 196.056858 \r\nL 180.923623 193.912849 \r\nL 181.051293 198.702708 \r\nL 181.178962 193.193375 \r\nL 181.56197 199.342689 \r\nL 181.689639 202.373669 \r\nL 181.817309 197.646748 \r\nL 181.944978 199.844313 \r\nL 182.072647 205.20841 \r\nL 182.327986 194.001092 \r\nL 182.455655 192.125056 \r\nL 182.710994 195.561325 \r\nL 182.838663 200.217329 \r\nL 183.094002 195.066211 \r\nL 183.221671 196.210146 \r\nL 183.34934 195.49554 \r\nL 183.604679 191.016217 \r\nL 183.732348 199.497817 \r\nL 183.860018 190.796584 \r\nL 183.987687 199.645398 \r\nL 184.115356 192.167982 \r\nL 184.243025 206.434351 \r\nL 184.370695 191.179456 \r\nL 184.498364 206.126542 \r\nL 184.753703 193.446784 \r\nL 184.881372 194.908281 \r\nL 185.009041 193.048631 \r\nL 185.136711 200.327181 \r\nL 185.26438 193.890556 \r\nL 185.392049 201.476644 \r\nL 185.519719 194.945689 \r\nL 185.647388 205.041797 \r\nL 185.775057 198.661084 \r\nL 185.902727 199.646624 \r\nL 186.030396 198.894033 \r\nL 186.158065 206.447874 \r\nL 186.285734 193.721149 \r\nL 186.413404 196.086563 \r\nL 186.541073 191.609049 \r\nL 186.668742 197.236448 \r\nL 186.796412 193.874912 \r\nL 186.924081 204.156665 \r\nL 187.17942 195.219228 \r\nL 187.307089 191.599491 \r\nL 187.434758 197.82174 \r\nL 187.690097 192.795478 \r\nL 187.817766 196.787001 \r\nL 187.945435 196.684322 \r\nL 188.073105 194.626953 \r\nL 188.456113 201.915488 \r\nL 188.711451 198.572324 \r\nL 188.839121 195.697744 \r\nL 188.96679 196.146384 \r\nL 189.094459 194.847396 \r\nL 189.222129 202.298044 \r\nL 189.349798 190.913778 \r\nL 189.477467 201.337296 \r\nL 189.605137 198.727803 \r\nL 189.732806 204.56168 \r\nL 189.988144 198.886266 \r\nL 190.115814 199.70118 \r\nL 190.243483 208.570395 \r\nL 190.371152 192.982109 \r\nL 190.498822 194.302345 \r\nL 190.626491 190.704432 \r\nL 190.75416 199.22838 \r\nL 190.88183 197.495979 \r\nL 191.009499 203.003926 \r\nL 191.137168 196.508789 \r\nL 191.264838 197.671959 \r\nL 191.392507 192.723743 \r\nL 191.520176 196.355674 \r\nL 191.775515 196.552649 \r\nL 191.903184 198.005129 \r\nL 192.030853 197.871812 \r\nL 192.158523 191.987975 \r\nL 192.286192 203.026939 \r\nL 192.413861 201.967982 \r\nL 192.541531 195.062595 \r\nL 192.6692 202.276712 \r\nL 192.796869 200.959748 \r\nL 193.052208 195.537752 \r\nL 193.179877 195.161689 \r\nL 193.307547 198.325599 \r\nL 193.435216 198.314155 \r\nL 193.562885 200.66838 \r\nL 193.690554 200.092923 \r\nL 193.818224 203.036214 \r\nL 194.073562 200.689195 \r\nL 194.201232 205.581257 \r\nL 194.328901 203.767094 \r\nL 194.58424 193.205936 \r\nL 194.711909 195.63153 \r\nL 194.839578 192.728935 \r\nL 194.967248 204.337835 \r\nL 195.094917 201.250173 \r\nL 195.222586 195.324148 \r\nL 195.350255 200.088869 \r\nL 195.477925 193.397203 \r\nL 195.605594 196.35549 \r\nL 195.733263 196.19086 \r\nL 195.988602 201.280859 \r\nL 196.243941 190.046396 \r\nL 196.37161 208.908117 \r\nL 196.626949 195.684554 \r\nL 196.754618 204.462345 \r\nL 196.882287 197.935342 \r\nL 197.009957 199.706891 \r\nL 197.137626 195.208692 \r\nL 197.265295 194.660633 \r\nL 197.392964 200.37664 \r\nL 197.520634 197.826833 \r\nL 197.775972 204.134172 \r\nL 197.903642 200.323345 \r\nL 198.031311 204.191943 \r\nL 198.15898 200.127632 \r\nL 198.28665 204.820133 \r\nL 198.669658 193.501259 \r\nL 198.797327 196.814895 \r\nL 198.924996 195.443878 \r\nL 199.052665 206.67712 \r\nL 199.308004 194.205945 \r\nL 199.435673 201.804528 \r\nL 199.691012 192.568071 \r\nL 199.818681 198.744809 \r\nL 199.946351 197.058148 \r\nL 200.07402 199.707756 \r\nL 200.201689 198.455333 \r\nL 200.329359 193.648355 \r\nL 200.457028 210.001356 \r\nL 200.584697 197.301302 \r\nL 200.712367 203.232182 \r\nL 200.967705 196.367466 \r\nL 201.095374 200.468055 \r\nL 201.223044 196.638654 \r\nL 201.350713 199.575132 \r\nL 201.478382 196.028989 \r\nL 201.733721 200.814826 \r\nL 201.98906 205.188897 \r\nL 202.116729 200.292938 \r\nL 202.372068 207.463084 \r\nL 202.627406 197.134739 \r\nL 202.755076 195.248474 \r\nL 202.882745 195.770392 \r\nL 203.010414 198.418346 \r\nL 203.138083 203.909839 \r\nL 203.393422 197.884287 \r\nL 203.521091 200.144019 \r\nL 203.648761 198.74634 \r\nL 203.904099 194.376023 \r\nL 204.031769 203.258739 \r\nL 204.159438 194.232317 \r\nL 204.287107 202.772669 \r\nL 204.414777 196.672355 \r\nL 204.542446 210.019616 \r\nL 204.670115 194.063063 \r\nL 204.797784 208.047432 \r\nL 205.053123 196.922645 \r\nL 205.180792 198.700051 \r\nL 205.308462 195.732823 \r\nL 205.436131 202.742339 \r\nL 205.5638 196.407877 \r\nL 205.69147 205.622143 \r\nL 205.819139 197.724464 \r\nL 205.946808 208.109472 \r\nL 206.074478 200.935665 \r\nL 206.202147 202.926591 \r\nL 206.329816 201.786499 \r\nL 206.457486 209.078169 \r\nL 206.585155 197.21605 \r\nL 206.712824 197.813955 \r\nL 206.840493 194.478927 \r\nL 206.968163 199.638018 \r\nL 207.095832 196.188223 \r\nL 207.223501 207.51536 \r\nL 207.47884 197.668454 \r\nL 207.606509 195.670938 \r\nL 207.734179 201.058728 \r\nL 207.989517 195.779401 \r\nL 208.117187 200.586881 \r\nL 208.244856 200.06598 \r\nL 208.372525 197.506721 \r\nL 208.627864 204.700922 \r\nL 209.010872 201.343535 \r\nL 209.138541 198.751631 \r\nL 209.26621 199.420001 \r\nL 209.39388 198.22961 \r\nL 209.521549 205.011261 \r\nL 209.649218 193.986259 \r\nL 209.776888 204.487824 \r\nL 209.904557 201.457312 \r\nL 210.032226 207.380549 \r\nL 210.287565 201.526653 \r\nL 210.415234 202.330067 \r\nL 210.542903 211.388297 \r\nL 210.670573 196.528056 \r\nL 210.798242 196.307062 \r\nL 210.925911 192.73633 \r\nL 211.053581 201.789751 \r\nL 211.18125 200.120585 \r\nL 211.308919 206.033006 \r\nL 211.436589 199.478648 \r\nL 211.564258 200.344838 \r\nL 211.691927 196.749969 \r\nL 211.947266 199.476514 \r\nL 212.074935 199.545041 \r\nL 212.202604 201.878697 \r\nL 212.330274 200.850368 \r\nL 212.457943 194.771798 \r\nL 212.585612 206.580316 \r\nL 212.713282 205.591382 \r\nL 212.840951 197.036512 \r\nL 212.96862 204.66441 \r\nL 213.09629 204.112785 \r\nL 213.351628 198.753414 \r\nL 213.479298 198.121172 \r\nL 213.606967 201.07781 \r\nL 213.734636 201.106545 \r\nL 213.862306 203.470208 \r\nL 213.989975 202.958781 \r\nL 214.117644 205.120038 \r\nL 214.372983 202.823582 \r\nL 214.500652 208.120216 \r\nL 214.628321 206.410392 \r\nL 214.88366 194.686463 \r\nL 215.011329 198.115647 \r\nL 215.138999 194.053785 \r\nL 215.266668 207.150176 \r\nL 215.522007 199.07404 \r\nL 215.649676 202.565079 \r\nL 215.777345 197.38366 \r\nL 215.905014 199.169141 \r\nL 216.032684 199.381554 \r\nL 216.288022 203.688436 \r\nL 216.415692 200.209993 \r\nL 216.543361 192.514058 \r\nL 216.67103 211.379121 \r\nL 216.926369 197.794536 \r\nL 217.054038 207.049376 \r\nL 217.181708 200.817233 \r\nL 217.309377 202.77244 \r\nL 217.437046 197.924611 \r\nL 217.564716 197.433718 \r\nL 217.692385 203.289516 \r\nL 217.820054 200.864894 \r\nL 217.947723 203.077875 \r\nL 218.075393 207.308425 \r\nL 218.203062 203.360232 \r\nL 218.330731 206.898954 \r\nL 218.458401 203.352407 \r\nL 218.58607 207.324961 \r\nL 218.969078 195.352708 \r\nL 219.096747 198.566474 \r\nL 219.224417 198.052433 \r\nL 219.352086 209.24125 \r\nL 219.607424 196.924838 \r\nL 219.735094 205.433803 \r\nL 219.990432 195.270786 \r\nL 220.118102 201.663508 \r\nL 220.245771 200.496686 \r\nL 220.37344 201.999382 \r\nL 220.50111 201.138608 \r\nL 220.628779 195.539095 \r\nL 220.756448 213.524731 \r\nL 220.884118 200.609584 \r\nL 221.011787 205.185835 \r\nL 221.267126 198.776959 \r\nL 221.394795 203.730124 \r\nL 221.522464 199.618586 \r\nL 221.650133 201.796816 \r\nL 221.777803 199.173824 \r\nL 221.905472 204.378222 \r\nL 222.033141 203.504503 \r\nL 222.28848 207.612824 \r\nL 222.416149 202.930116 \r\nL 222.543819 204.668001 \r\nL 222.671488 209.742431 \r\nL 222.926827 200.247903 \r\nL 223.054496 197.355279 \r\nL 223.182165 197.284314 \r\nL 223.437504 206.789693 \r\nL 223.692842 200.510562 \r\nL 223.820512 203.661681 \r\nL 224.20352 197.423554 \r\nL 224.331189 205.606088 \r\nL 224.458858 197.543563 \r\nL 224.586528 204.777262 \r\nL 224.714197 198.646919 \r\nL 224.841866 213.274487 \r\nL 224.969536 196.961411 \r\nL 225.097205 210.022167 \r\nL 225.352543 199.135123 \r\nL 225.480213 201.566834 \r\nL 225.607882 196.999175 \r\nL 225.735551 204.469931 \r\nL 225.863221 199.821785 \r\nL 225.99089 209.013061 \r\nL 226.118559 199.585648 \r\nL 226.246229 211.444695 \r\nL 226.373898 203.413828 \r\nL 226.501567 205.728968 \r\nL 226.629237 204.797672 \r\nL 226.756906 211.202186 \r\nL 226.884575 201.578265 \r\nL 227.012245 201.035184 \r\nL 227.139914 197.340893 \r\nL 227.267583 201.851458 \r\nL 227.395252 199.240821 \r\nL 227.522922 210.396026 \r\nL 227.77826 200.619311 \r\nL 227.90593 199.433169 \r\nL 228.033599 203.633412 \r\nL 228.288938 198.727776 \r\nL 228.416607 203.04952 \r\nL 228.544276 202.7788 \r\nL 228.671946 199.081682 \r\nL 228.927284 207.591432 \r\nL 229.054953 205.580982 \r\nL 229.182623 205.751083 \r\nL 229.437961 200.701555 \r\nL 229.565631 202.461886 \r\nL 229.6933 199.440928 \r\nL 229.820969 207.735044 \r\nL 229.948639 198.17814 \r\nL 230.076308 206.407869 \r\nL 230.203977 201.347674 \r\nL 230.331647 209.192222 \r\nL 230.586985 202.541872 \r\nL 230.714655 205.304124 \r\nL 230.842324 213.235112 \r\nL 231.097662 199.330374 \r\nL 231.225332 195.607923 \r\nL 231.353001 205.374766 \r\nL 231.48067 203.483173 \r\nL 231.60834 208.899421 \r\nL 231.736009 202.331039 \r\nL 231.863678 202.608314 \r\nL 231.991348 200.61268 \r\nL 232.119017 201.128241 \r\nL 232.246686 202.133062 \r\nL 232.374356 201.985766 \r\nL 232.502025 204.43783 \r\nL 232.629694 203.229961 \r\nL 232.757363 195.893107 \r\nL 232.885033 210.24522 \r\nL 233.012702 207.497616 \r\nL 233.140371 198.883738 \r\nL 233.268041 206.390646 \r\nL 233.39571 206.220564 \r\nL 233.523379 202.118967 \r\nL 233.778718 201.471746 \r\nL 233.906387 204.513753 \r\nL 234.034057 204.567056 \r\nL 234.417065 208.442295 \r\nL 234.672403 204.888367 \r\nL 234.800072 210.453472 \r\nL 234.927742 210.001912 \r\nL 235.18308 197.083095 \r\nL 235.31075 201.419196 \r\nL 235.438419 198.112075 \r\nL 235.566088 209.921965 \r\nL 235.821427 203.063507 \r\nL 235.949096 204.765955 \r\nL 236.076766 200.071717 \r\nL 236.332104 203.114101 \r\nL 236.459773 202.928649 \r\nL 236.587443 205.466392 \r\nL 236.715112 203.375592 \r\nL 236.842781 194.138286 \r\nL 236.970451 216.184205 \r\nL 237.225789 199.361901 \r\nL 237.353459 208.927318 \r\nL 237.481128 202.607989 \r\nL 237.608797 205.43694 \r\nL 237.864136 199.471975 \r\nL 237.991805 206.529298 \r\nL 238.119475 203.786463 \r\nL 238.247144 203.950408 \r\nL 238.374813 209.654565 \r\nL 238.502482 205.284254 \r\nL 238.630152 208.574416 \r\nL 238.757821 204.639582 \r\nL 238.88549 209.259985 \r\nL 239.01316 207.551349 \r\nL 239.268498 197.08548 \r\nL 239.396168 203.785918 \r\nL 239.523837 200.766564 \r\nL 239.651506 211.440614 \r\nL 239.906845 200.174368 \r\nL 240.034514 209.024978 \r\nL 240.289853 197.731853 \r\nL 240.417522 204.18915 \r\nL 240.545191 203.189007 \r\nL 240.80053 204.173738 \r\nL 240.928199 198.972514 \r\nL 241.055869 217.654689 \r\nL 241.183538 202.408496 \r\nL 241.311207 206.878524 \r\nL 241.566546 201.242816 \r\nL 241.694215 206.129047 \r\nL 241.821885 202.715571 \r\nL 241.949554 205.154387 \r\nL 242.077223 201.720719 \r\nL 242.204892 207.073763 \r\nL 242.332562 205.35452 \r\nL 242.5879 211.942919 \r\nL 242.71557 205.018651 \r\nL 242.843239 205.959401 \r\nL 242.970908 211.483029 \r\nL 243.353916 199.49505 \r\nL 243.481586 200.413812 \r\nL 243.736924 209.692522 \r\nL 244.119932 198.814696 \r\nL 244.247601 194.483721 \r\nL 244.50294 195.657412 \r\nL 244.630609 204.799038 \r\nL 244.758279 192.347764 \r\nL 244.885948 203.067533 \r\nL 245.013617 197.83659 \r\nL 245.141287 214.867883 \r\nL 245.268956 195.771726 \r\nL 245.396625 211.799367 \r\nL 245.651964 202.803369 \r\nL 245.779633 202.841454 \r\nL 245.907302 200.541115 \r\nL 246.034972 207.116447 \r\nL 246.162641 202.131054 \r\nL 246.29031 210.820413 \r\nL 246.41798 201.745063 \r\nL 246.545649 214.21966 \r\nL 246.800988 206.932566 \r\nL 246.928657 205.533773 \r\nL 247.056326 212.631251 \r\nL 247.311665 204.172896 \r\nL 247.439334 199.109073 \r\nL 247.567004 204.902977 \r\nL 247.694673 203.287883 \r\nL 247.822342 213.360914 \r\nL 248.077681 202.611725 \r\nL 248.20535 201.904589 \r\nL 248.333019 205.388767 \r\nL 248.460689 202.347836 \r\nL 248.588358 201.972072 \r\nL 248.843697 204.102602 \r\nL 248.971366 200.733323 \r\nL 249.226705 210.590372 \r\nL 249.354374 207.559352 \r\nL 249.482043 208.679642 \r\nL 249.737382 204.182328 \r\nL 249.865051 204.762646 \r\nL 249.99272 203.663151 \r\nL 250.12039 210.121925 \r\nL 250.248059 200.508045 \r\nL 250.375728 208.487833 \r\nL 250.503398 204.922906 \r\nL 250.631067 211.931335 \r\nL 250.886406 204.604616 \r\nL 251.014075 207.337034 \r\nL 251.141744 215.98208 \r\nL 251.397083 201.652853 \r\nL 251.524752 197.559396 \r\nL 251.652421 208.013893 \r\nL 251.780091 205.696325 \r\nL 251.90776 211.435236 \r\nL 252.035429 205.455268 \r\nL 252.163099 205.069892 \r\nL 252.418437 202.540276 \r\nL 252.801445 206.546979 \r\nL 252.929115 206.75423 \r\nL 253.056784 198.042744 \r\nL 253.184453 212.221701 \r\nL 253.312122 209.576535 \r\nL 253.439792 200.656329 \r\nL 253.567461 209.720226 \r\nL 253.69513 209.099258 \r\nL 253.8228 204.459964 \r\nL 253.950469 204.857758 \r\nL 254.078138 202.901781 \r\nL 254.333477 206.343121 \r\nL 254.461146 208.671893 \r\nL 254.588816 208.015716 \r\nL 254.716485 211.677864 \r\nL 254.844154 209.952242 \r\nL 254.971824 205.010662 \r\nL 255.227162 212.695186 \r\nL 255.482501 199.362669 \r\nL 255.61017 203.424005 \r\nL 255.737839 201.040731 \r\nL 255.865509 211.947153 \r\nL 256.120847 206.012109 \r\nL 256.248517 206.962004 \r\nL 256.376186 203.158883 \r\nL 256.503855 203.111959 \r\nL 256.886863 207.102191 \r\nL 257.014532 207.118716 \r\nL 257.142202 196.641243 \r\nL 257.269871 218.807964 \r\nL 257.52521 202.531292 \r\nL 257.652879 211.640884 \r\nL 257.780548 205.863313 \r\nL 257.908218 208.881897 \r\nL 258.163556 202.710689 \r\nL 258.291226 208.05758 \r\nL 258.418895 206.329018 \r\nL 258.546564 206.24615 \r\nL 258.674234 212.246203 \r\nL 258.801903 210.010939 \r\nL 258.929572 210.828241 \r\nL 259.057241 205.417743 \r\nL 259.184911 211.06062 \r\nL 259.31258 210.70402 \r\nL 259.440249 207.458983 \r\nL 259.567919 200.078471 \r\nL 259.695588 205.428746 \r\nL 259.823257 203.705938 \r\nL 259.950927 213.719558 \r\nL 260.078596 210.738159 \r\nL 260.206265 202.561244 \r\nL 260.333935 210.727776 \r\nL 260.589273 199.108603 \r\nL 260.844612 207.581966 \r\nL 260.972281 206.155497 \r\nL 261.09995 206.985725 \r\nL 261.22762 199.351407 \r\nL 261.355289 220.351031 \r\nL 261.482958 203.931208 \r\nL 261.610628 209.8252 \r\nL 261.865966 204.525836 \r\nL 261.993636 208.935612 \r\nL 262.121305 205.524838 \r\nL 262.248974 207.316987 \r\nL 262.376644 203.341252 \r\nL 262.504313 209.056908 \r\nL 262.631982 208.468068 \r\nL 262.887321 214.391382 \r\nL 263.01499 207.288811 \r\nL 263.142659 207.491179 \r\nL 263.270329 213.478863 \r\nL 263.653337 202.874663 \r\nL 263.908675 206.416808 \r\nL 264.036345 211.837232 \r\nL 264.164014 209.694782 \r\nL 264.291683 205.531171 \r\nL 264.419353 209.039542 \r\nL 264.674691 200.889473 \r\nL 264.80236 202.938168 \r\nL 264.93003 211.456671 \r\nL 265.057699 203.354956 \r\nL 265.185368 210.588111 \r\nL 265.313038 202.848064 \r\nL 265.440707 219.832411 \r\nL 265.568376 200.672395 \r\nL 265.696046 214.421361 \r\nL 265.951384 205.869633 \r\nL 266.079054 206.685976 \r\nL 266.206723 204.279185 \r\nL 266.334392 209.284303 \r\nL 266.462061 204.513836 \r\nL 266.589731 212.436908 \r\nL 266.7174 203.498928 \r\nL 266.845069 214.55043 \r\nL 266.972739 209.428982 \r\nL 267.100408 209.720287 \r\nL 267.228077 208.051772 \r\nL 267.355747 214.032306 \r\nL 267.738755 201.418436 \r\nL 267.866424 208.244632 \r\nL 267.994093 205.172571 \r\nL 268.121763 215.968848 \r\nL 268.377101 205.749058 \r\nL 268.50477 205.332093 \r\nL 268.63244 208.414154 \r\nL 268.760109 204.027821 \r\nL 269.143117 208.692166 \r\nL 269.270786 203.67866 \r\nL 269.526125 212.699404 \r\nL 269.653794 210.068448 \r\nL 269.781464 211.403726 \r\nL 269.909133 207.616886 \r\nL 270.036802 207.222388 \r\nL 270.164471 208.315403 \r\nL 270.292141 204.730869 \r\nL 270.41981 211.085386 \r\nL 270.547479 202.02011 \r\nL 270.675149 210.907225 \r\nL 270.802818 208.557139 \r\nL 270.930487 216.055172 \r\nL 271.185826 208.021948 \r\nL 271.313495 208.099062 \r\nL 271.441165 218.317967 \r\nL 271.696503 204.523856 \r\nL 271.824173 199.86753 \r\nL 271.951842 211.826544 \r\nL 272.079511 208.7562 \r\nL 272.20718 214.813396 \r\nL 272.33485 207.621343 \r\nL 272.590188 205.851118 \r\nL 272.717858 203.784146 \r\nL 272.845527 205.424697 \r\nL 272.973196 208.682784 \r\nL 273.100866 209.043987 \r\nL 273.228535 210.185625 \r\nL 273.356204 201.762696 \r\nL 273.483874 215.063313 \r\nL 273.611543 212.457585 \r\nL 273.739212 203.088801 \r\nL 273.866881 213.32649 \r\nL 274.249889 207.099752 \r\nL 274.377559 205.057403 \r\nL 274.760567 208.880465 \r\nL 274.888236 209.053611 \r\nL 275.015905 212.099446 \r\nL 275.143575 211.402674 \r\nL 275.271244 207.723562 \r\nL 275.398913 214.349341 \r\nL 275.526583 215.153444 \r\nL 275.781921 199.335381 \r\nL 275.90959 203.847233 \r\nL 276.03726 200.891752 \r\nL 276.164929 212.564377 \r\nL 276.675606 205.826954 \r\nL 276.803276 205.296196 \r\nL 276.930945 206.521532 \r\nL 277.186284 210.306372 \r\nL 277.313953 211.046946 \r\nL 277.441622 198.205752 \r\nL 277.569291 220.083292 \r\nL 277.82463 205.255086 \r\nL 277.952299 214.454513 \r\nL 278.079969 207.969781 \r\nL 278.207638 212.674538 \r\nL 278.462977 203.890878 \r\nL 278.590646 209.018668 \r\nL 278.718315 206.880795 \r\nL 278.973654 214.205138 \r\nL 279.101323 213.554618 \r\nL 279.228993 214.336299 \r\nL 279.356662 208.024547 \r\nL 279.484331 213.388823 \r\nL 279.612 212.877733 \r\nL 279.73967 211.028859 \r\nL 279.867339 201.684299 \r\nL 279.995008 208.622779 \r\nL 280.122678 205.059384 \r\nL 280.250347 216.528772 \r\nL 280.505686 206.23576 \r\nL 280.633355 213.121477 \r\nL 280.888694 200.96494 \r\nL 281.144032 209.785827 \r\nL 281.271701 208.483946 \r\nL 281.399371 211.918005 \r\nL 281.52704 202.302597 \r\nL 281.654709 223.478169 \r\nL 281.782379 205.970959 \r\nL 281.910048 212.026356 \r\nL 282.165387 207.251313 \r\nL 282.293056 212.219708 \r\nL 282.420725 207.952484 \r\nL 282.548395 208.306967 \r\nL 282.676064 203.898755 \r\nL 282.803733 209.399735 \r\nL 282.931403 209.936129 \r\nL 283.059072 212.249243 \r\nL 283.186741 216.786981 \r\nL 283.31441 209.713859 \r\nL 283.44208 210.840963 \r\nL 283.569749 214.647782 \r\nL 283.697418 213.299624 \r\nL 283.952757 204.146333 \r\nL 284.208096 207.673981 \r\nL 284.335765 214.377425 \r\nL 284.591104 208.784833 \r\nL 284.718773 211.718989 \r\nL 284.846442 208.659792 \r\nL 284.974112 202.479727 \r\nL 285.101781 205.468407 \r\nL 285.22945 213.359493 \r\nL 285.357119 205.541079 \r\nL 285.484789 214.484795 \r\nL 285.612458 204.381054 \r\nL 285.740127 223.11046 \r\nL 285.867797 202.557519 \r\nL 285.995466 216.620698 \r\nL 286.250805 208.36534 \r\nL 286.378474 209.922609 \r\nL 286.506143 206.386723 \r\nL 286.633813 210.489378 \r\nL 286.761482 204.016581 \r\nL 286.889151 213.004011 \r\nL 287.01682 207.626453 \r\nL 287.14449 217.337725 \r\nL 287.399828 210.929091 \r\nL 287.527498 210.785299 \r\nL 287.655167 215.247524 \r\nL 287.910506 209.059455 \r\nL 288.038175 202.510825 \r\nL 288.165844 211.554584 \r\nL 288.293514 206.862367 \r\nL 288.421183 216.772489 \r\nL 288.676522 205.742039 \r\nL 288.93186 210.867762 \r\nL 289.059529 205.610975 \r\nL 289.314868 209.886616 \r\nL 289.442537 210.945 \r\nL 289.570207 205.148949 \r\nL 289.825545 216.445 \r\nL 289.953215 211.451073 \r\nL 290.080884 213.467107 \r\nL 290.208553 209.799512 \r\nL 290.336223 209.744158 \r\nL 290.463892 210.568652 \r\nL 290.591561 206.963822 \r\nL 290.71923 211.186862 \r\nL 290.8469 202.248264 \r\nL 290.974569 212.357134 \r\nL 291.102238 210.177761 \r\nL 291.229908 217.91402 \r\nL 291.485246 210.349496 \r\nL 291.612916 211.035881 \r\nL 291.740585 220.132807 \r\nL 291.995924 207.492083 \r\nL 292.123593 201.158941 \r\nL 292.251262 213.937217 \r\nL 292.378932 209.715814 \r\nL 292.506601 216.462414 \r\nL 292.63427 209.2332 \r\nL 292.761939 209.254012 \r\nL 292.889609 210.341085 \r\nL 293.017278 206.770312 \r\nL 293.144947 207.589001 \r\nL 293.272617 211.551091 \r\nL 293.400286 210.476438 \r\nL 293.527955 212.012978 \r\nL 293.655625 203.448293 \r\nL 293.783294 216.277563 \r\nL 293.910963 214.911624 \r\nL 294.038633 205.475526 \r\nL 294.166302 215.350582 \r\nL 294.54931 208.834515 \r\nL 294.676979 206.759857 \r\nL 294.932318 207.634909 \r\nL 295.059987 211.629993 \r\nL 295.187656 212.088791 \r\nL 295.315326 216.299197 \r\nL 295.570664 211.68339 \r\nL 295.826003 217.124217 \r\nL 295.953672 212.602659 \r\nL 296.081342 203.922382 \r\nL 296.209011 206.470148 \r\nL 296.33668 204.287147 \r\nL 296.464349 216.724876 \r\nL 296.719688 207.890935 \r\nL 296.847357 211.208043 \r\nL 297.102696 207.203051 \r\nL 297.613373 213.497634 \r\nL 297.741043 199.341802 \r\nL 297.868712 222.709519 \r\nL 298.12405 207.301817 \r\nL 298.25172 216.501384 \r\nL 298.379389 210.758329 \r\nL 298.507058 214.341078 \r\nL 298.762397 205.804605 \r\nL 298.890066 209.371264 \r\nL 299.017736 207.279869 \r\nL 299.273074 216.274645 \r\nL 299.400744 215.815676 \r\nL 299.528413 216.337496 \r\nL 299.656082 211.66768 \r\nL 299.783752 215.185434 \r\nL 299.911421 214.585321 \r\nL 300.03909 213.273313 \r\nL 300.166759 204.358248 \r\nL 300.294429 210.602467 \r\nL 300.422098 206.251723 \r\nL 300.549767 218.369141 \r\nL 300.805106 206.013147 \r\nL 300.932775 216.174603 \r\nL 301.188114 203.456567 \r\nL 301.443453 212.855868 \r\nL 301.571122 209.672858 \r\nL 301.698791 212.880758 \r\nL 301.82646 203.170732 \r\nL 301.95413 224.885693 \r\nL 302.081799 209.61078 \r\nL 302.209468 213.022473 \r\nL 302.464807 209.954757 \r\nL 302.592476 213.695346 \r\nL 302.975484 204.568103 \r\nL 303.230823 211.447137 \r\nL 303.486162 219.811969 \r\nL 303.613831 211.821752 \r\nL 303.7415 213.460233 \r\nL 303.869169 217.072651 \r\nL 303.996839 216.20011 \r\nL 304.252177 206.790961 \r\nL 304.379847 210.266443 \r\nL 304.507516 208.559275 \r\nL 304.635185 216.60644 \r\nL 304.890524 209.460622 \r\nL 305.018193 214.740476 \r\nL 305.145863 212.163538 \r\nL 305.273532 205.03299 \r\nL 305.401201 207.914789 \r\nL 305.528871 215.671469 \r\nL 305.65654 206.476532 \r\nL 305.784209 216.055817 \r\nL 305.911878 205.840786 \r\nL 306.039548 225.629313 \r\nL 306.167217 204.444979 \r\nL 306.294886 217.912585 \r\nL 306.550225 210.451002 \r\nL 306.677894 211.581312 \r\nL 306.805564 208.087339 \r\nL 306.933233 211.690646 \r\nL 307.060902 205.321535 \r\nL 307.188572 214.66924 \r\nL 307.316241 210.064205 \r\nL 307.44391 219.319965 \r\nL 307.699249 213.187529 \r\nL 307.826918 214.197106 \r\nL 307.954587 217.857541 \r\nL 308.209926 212.771175 \r\nL 308.337595 204.112709 \r\nL 308.465265 214.923014 \r\nL 308.592934 207.839869 \r\nL 308.720603 219.89993 \r\nL 308.975942 209.124481 \r\nL 309.231281 214.115126 \r\nL 309.35895 207.199997 \r\nL 309.486619 211.558709 \r\nL 309.614288 211.91883 \r\nL 309.741958 211.857826 \r\nL 309.869627 207.848846 \r\nL 310.124966 218.443208 \r\nL 310.252635 213.81695 \r\nL 310.380304 216.269476 \r\nL 310.507974 211.891995 \r\nL 310.635643 213.310996 \r\nL 310.763312 211.875164 \r\nL 310.890982 208.988519 \r\nL 311.018651 212.223129 \r\nL 311.14632 204.524344 \r\nL 311.273989 215.122083 \r\nL 311.401659 212.53885 \r\nL 311.529328 220.576514 \r\nL 311.784667 212.45746 \r\nL 311.912336 213.057605 \r\nL 312.040005 221.639119 \r\nL 312.423013 200.917713 \r\nL 312.550683 216.538434 \r\nL 312.678352 210.889688 \r\nL 312.806021 217.301272 \r\nL 312.933691 211.195311 \r\nL 313.06136 210.770433 \r\nL 313.189029 213.069976 \r\nL 313.316698 208.659298 \r\nL 313.444368 210.013974 \r\nL 313.572037 213.791218 \r\nL 313.699706 212.750116 \r\nL 313.827376 214.351151 \r\nL 313.955045 205.061651 \r\nL 314.082714 218.117204 \r\nL 314.210384 216.805034 \r\nL 314.338053 207.550965 \r\nL 314.465722 218.234127 \r\nL 315.104069 208.594058 \r\nL 315.231738 209.096684 \r\nL 315.359407 214.156379 \r\nL 315.487077 214.4694 \r\nL 315.614746 219.15374 \r\nL 315.870085 212.70091 \r\nL 315.997754 218.422931 \r\nL 316.125423 218.67001 \r\nL 316.253093 215.8054 \r\nL 316.380762 207.827448 \r\nL 316.508431 209.172722 \r\nL 316.636101 205.83157 \r\nL 316.76377 218.633584 \r\nL 317.019108 212.663712 \r\nL 317.146778 213.798081 \r\nL 317.274447 210.644249 \r\nL 317.402116 210.574181 \r\nL 317.529786 211.189289 \r\nL 317.657455 213.992005 \r\nL 317.785124 214.17956 \r\nL 317.912794 215.665815 \r\nL 318.040463 202.47674 \r\nL 318.168132 222.66536 \r\nL 318.423471 209.074914 \r\nL 318.55114 217.438496 \r\nL 318.678809 213.463821 \r\nL 318.806479 216.082624 \r\nL 319.061817 206.848677 \r\nL 319.189487 211.547768 \r\nL 319.317156 209.479027 \r\nL 319.572495 218.738531 \r\nL 319.700164 217.710679 \r\nL 319.827833 217.932495 \r\nL 319.955503 212.929118 \r\nL 320.210841 217.036187 \r\nL 320.338511 216.962588 \r\nL 320.46618 206.389574 \r\nL 320.593849 214.412308 \r\nL 320.721518 207.469179 \r\nL 320.849188 220.178997 \r\nL 321.104526 208.536206 \r\nL 321.232196 217.769732 \r\nL 321.487534 205.097541 \r\nL 321.742873 215.321589 \r\nL 321.870542 211.90195 \r\nL 321.998212 215.286715 \r\nL 322.125881 204.648779 \r\nL 322.25355 225.606271 \r\nL 322.381219 210.438862 \r\nL 322.508889 215.664343 \r\nL 322.636558 212.811908 \r\nL 322.764227 213.224651 \r\nL 322.891897 214.686279 \r\nL 323.019566 210.384798 \r\nL 323.147235 210.792304 \r\nL 323.274905 206.645354 \r\nL 323.530243 214.263277 \r\nL 323.657913 216.753097 \r\nL 323.785582 222.175866 \r\nL 323.913251 213.413375 \r\nL 324.16859 218.083337 \r\nL 324.423928 214.589565 \r\nL 324.551598 207.950704 \r\nL 324.679267 211.495267 \r\nL 324.806936 208.052118 \r\nL 324.934606 218.218713 \r\nL 325.189944 210.888705 \r\nL 325.317614 216.224412 \r\nL 325.445283 214.299322 \r\nL 325.572952 207.683353 \r\nL 325.828291 217.693881 \r\nL 325.95596 207.225529 \r\nL 326.083629 219.137112 \r\nL 326.211299 207.663319 \r\nL 326.338968 227.305886 \r\nL 326.466637 206.592109 \r\nL 326.594307 220.838506 \r\nL 326.849645 213.61568 \r\nL 327.104984 209.585734 \r\nL 327.232653 213.481604 \r\nL 327.360323 207.31113 \r\nL 327.487992 216.584052 \r\nL 327.615661 211.558433 \r\nL 327.743331 222.281751 \r\nL 327.998669 212.743111 \r\nL 328.254008 218.847597 \r\nL 328.509346 216.037253 \r\nL 328.637016 205.531458 \r\nL 328.764685 217.427397 \r\nL 328.892354 208.319912 \r\nL 329.020024 221.820225 \r\nL 329.275362 211.524436 \r\nL 329.403032 213.093386 \r\nL 329.530701 216.426372 \r\nL 329.65837 208.502097 \r\nL 329.78604 215.382343 \r\nL 329.913709 214.221876 \r\nL 330.041378 214.239648 \r\nL 330.169047 210.85783 \r\nL 330.296717 213.799498 \r\nL 330.424386 221.91598 \r\nL 330.552055 216.522597 \r\nL 330.679725 217.856232 \r\nL 330.807394 214.503363 \r\nL 330.935063 216.346733 \r\nL 331.190402 209.93011 \r\nL 331.318071 212.817536 \r\nL 331.445741 205.585153 \r\nL 331.57341 216.233281 \r\nL 331.701079 214.51503 \r\nL 331.828748 222.410138 \r\nL 332.084087 214.151459 \r\nL 332.211756 214.064117 \r\nL 332.339426 223.285802 \r\nL 332.467095 215.029413 \r\nL 332.594764 214.845851 \r\nL 332.722434 203.790295 \r\nL 332.850103 219.447647 \r\nL 332.977772 211.80498 \r\nL 333.105442 218.850163 \r\nL 333.36078 212.313802 \r\nL 333.48845 214.828262 \r\nL 333.616119 210.639613 \r\nL 333.871457 216.100834 \r\nL 333.999127 216.005482 \r\nL 334.126796 216.254802 \r\nL 334.254465 207.823291 \r\nL 334.382135 220.220019 \r\nL 334.509804 220.158938 \r\nL 334.637473 208.968489 \r\nL 334.765143 220.531777 \r\nL 334.892812 218.72816 \r\nL 335.27582 209.564386 \r\nL 335.403489 209.960633 \r\nL 335.531158 210.98089 \r\nL 335.914166 221.747451 \r\nL 336.169505 214.072475 \r\nL 336.424844 219.704296 \r\nL 336.552513 217.891897 \r\nL 336.680182 210.620547 \r\nL 336.807852 210.410546 \r\nL 336.935521 208.238342 \r\nL 337.06319 218.91115 \r\nL 337.318529 215.620259 \r\nL 337.446198 214.876673 \r\nL 337.573867 212.88171 \r\nL 337.701537 212.820203 \r\nL 337.829206 212.9725 \r\nL 338.084545 216.662815 \r\nL 338.212214 217.566602 \r\nL 338.339883 205.778649 \r\nL 338.467553 225.526805 \r\nL 338.722891 212.032596 \r\nL 338.850561 220.191667 \r\nL 338.97823 216.296307 \r\nL 339.105899 217.248585 \r\nL 339.361238 206.815406 \r\nL 339.488907 212.39507 \r\nL 339.616576 211.217063 \r\nL 339.999584 221.455703 \r\nL 340.127254 220.077922 \r\nL 340.254923 214.13352 \r\nL 340.510262 218.694053 \r\nL 340.637931 219.354913 \r\nL 340.7656 208.014119 \r\nL 340.89327 215.596973 \r\nL 341.020939 208.830666 \r\nL 341.148608 220.48198 \r\nL 341.276277 217.704035 \r\nL 341.403947 212.211911 \r\nL 341.531616 219.589807 \r\nL 341.786955 208.967307 \r\nL 342.042293 218.097668 \r\nL 342.169963 213.907993 \r\nL 342.297632 217.595635 \r\nL 342.425301 207.681312 \r\nL 342.552971 228.56482 \r\nL 342.68064 213.501294 \r\nL 342.808309 218.294261 \r\nL 343.063648 213.675556 \r\nL 343.191317 216.227767 \r\nL 343.574325 207.203396 \r\nL 343.829664 215.643992 \r\nL 343.957333 218.161768 \r\nL 344.085002 224.251062 \r\nL 344.212672 214.880163 \r\nL 344.59568 218.563701 \r\nL 344.723349 218.233098 \r\nL 344.851018 211.027638 \r\nL 344.978687 213.809227 \r\nL 345.106357 211.007816 \r\nL 345.234026 218.817736 \r\nL 345.489365 215.546194 \r\nL 345.617034 218.071914 \r\nL 345.872373 210.274831 \r\nL 346.000042 213.435077 \r\nL 346.127711 220.8968 \r\nL 346.255381 209.608321 \r\nL 346.38305 220.419075 \r\nL 346.510719 210.238911 \r\nL 346.638388 229.874489 \r\nL 346.766058 208.742274 \r\nL 346.893727 223.251004 \r\nL 347.149066 215.632268 \r\nL 347.276735 213.906717 \r\nL 347.404404 210.400504 \r\nL 347.532074 213.364128 \r\nL 347.659743 208.782527 \r\nL 347.787412 217.748923 \r\nL 347.915082 213.612465 \r\nL 348.042751 223.78374 \r\nL 348.29809 214.530403 \r\nL 348.553428 220.101547 \r\nL 348.681097 219.301302 \r\nL 348.808767 218.619023 \r\nL 348.936436 207.499724 \r\nL 349.064105 219.155215 \r\nL 349.191775 210.601108 \r\nL 349.319444 223.693904 \r\nL 349.574783 213.892981 \r\nL 349.702452 214.841185 \r\nL 349.830121 218.140772 \r\nL 349.957791 210.552313 \r\nL 350.08546 217.531623 \r\nL 350.340799 216.002465 \r\nL 350.468468 212.552134 \r\nL 350.723806 223.018995 \r\nL 350.851476 216.774797 \r\nL 350.979145 220.395477 \r\nL 351.106814 214.929438 \r\nL 351.234484 214.25242 \r\nL 351.362153 211.529419 \r\nL 351.489822 205.051744 \r\nL 351.617492 211.537046 \r\nL 351.745161 204.397831 \r\nL 351.87283 214.901408 \r\nL 352.0005 214.467065 \r\nL 352.128169 222.47835 \r\nL 352.255838 219.883516 \r\nL 352.383507 214.266493 \r\nL 352.511177 214.546044 \r\nL 352.638846 224.696751 \r\nL 352.766515 216.972781 \r\nL 352.894185 215.975494 \r\nL 353.021854 204.305576 \r\nL 353.149523 219.667715 \r\nL 353.277193 215.348927 \r\nL 353.404862 220.03395 \r\nL 353.660201 214.66026 \r\nL 353.78787 216.278999 \r\nL 353.915539 213.753068 \r\nL 354.043209 214.469214 \r\nL 354.170878 219.488122 \r\nL 354.298547 218.21981 \r\nL 354.426216 218.263454 \r\nL 354.553886 210.290172 \r\nL 354.681555 222.085947 \r\nL 354.809224 221.829272 \r\nL 354.936894 211.25024 \r\nL 355.064563 222.466314 \r\nL 355.192232 220.66072 \r\nL 355.57524 209.336991 \r\nL 355.830579 212.276345 \r\nL 356.213587 223.665309 \r\nL 356.468925 215.017891 \r\nL 356.724264 220.344981 \r\nL 356.851933 220.128284 \r\nL 356.979603 210.620924 \r\nL 357.107272 212.062662 \r\nL 357.234941 210.385023 \r\nL 357.362611 220.55745 \r\nL 357.617949 217.782919 \r\nL 357.873288 214.459081 \r\nL 358.000957 215.781391 \r\nL 358.128626 215.224125 \r\nL 358.256296 219.477374 \r\nL 358.383965 218.613403 \r\nL 358.511634 219.349027 \r\nL 358.639304 207.125753 \r\nL 358.766973 227.997004 \r\nL 359.022312 214.153346 \r\nL 359.149981 222.117111 \r\nL 359.27765 215.959817 \r\nL 359.40532 218.087208 \r\nL 359.660658 207.377404 \r\nL 359.788327 213.160306 \r\nL 359.915997 212.110504 \r\nL 360.299005 222.273455 \r\nL 360.426674 222.085544 \r\nL 360.554343 213.586628 \r\nL 360.682013 218.583324 \r\nL 360.809682 219.033839 \r\nL 360.937351 221.045195 \r\nL 361.065021 209.459404 \r\nL 361.19269 216.525453 \r\nL 361.320359 211.55673 \r\nL 361.448029 221.658976 \r\nL 361.575698 219.742064 \r\nL 361.703367 215.158374 \r\nL 361.831036 220.350662 \r\nL 362.086375 211.706171 \r\nL 362.341714 221.276133 \r\nL 362.469383 215.939999 \r\nL 362.597052 219.478484 \r\nL 362.724722 210.15203 \r\nL 362.852391 229.24314 \r\nL 362.98006 214.534708 \r\nL 363.10773 220.366518 \r\nL 363.235399 216.409964 \r\nL 363.363068 216.356693 \r\nL 363.363068 216.356693 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 43.78125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 239.758125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 239.758125 \r\nL 378.58125 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 22.318125 \r\nL 378.58125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_17\">\r\n    <!-- Training loss -->\r\n    <g transform=\"translate(174.014063 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-84\"/>\r\n     <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"394.527344\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"426.314453\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"454.097656\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"515.279297\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"567.378906\" xlink:href=\"#DejaVuSans-115\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p873a848bd2\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "nb_steps_loss_sum = 10\n",
    "loss = training(batch_size=batch_size, nb_steps_loss_sum=nb_steps_loss_sum,epochs=epochs)\n",
    "\n",
    "# Plotting the loss over training\n",
    "plt.figure()\n",
    "plt.plot(range(0, len(loss)), loss)\n",
    "plt.xlabel(f\"Batches/{nb_steps_loss_sum}\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScore(X, y,batch_size):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, X.shape[0], batch_size):\n",
    "            \n",
    "            output = my_nn(X.float())\n",
    "            max_pred = torch.max(output, 1)\n",
    "            max_target = torch.max(y, 1)\n",
    "            if max_pred[1][idx] == max_target[1][idx]:\n",
    "                correct += 1\n",
    "            total = total + 1\n",
    "\n",
    "    accuracy = correct/total * 100\n",
    "    print(f\"Accuracy of the network on the {total} samples: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 318 samples: 77.99%\n",
      "Accuracy of the network on the 80 samples: 63.75%\n"
     ]
    }
   ],
   "source": [
    "computeScore(X_train, y_train,batch_size)\n",
    "computeScore(X_test, y_test,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-03-03 16:01:32,597]\u001b[0m A new study created in memory with name: no-name-5dc963a4-dd7e-4a1d-90e9-7b6721e85abc\u001b[0m\n",
      "\u001b[33m[W 2021-03-03 16:01:32,600]\u001b[0m Trial 0 failed because of the following error: NameError(\"name 'accuracy' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Pierre\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\_optimize.py\", line 211, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-21-2d4844b43f13>\", line 13, in objective\n",
      "    return accuracy\n",
      "NameError: name 'accuracy' is not defined\u001b[0m\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-363b30d9be2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         )\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-2d4844b43f13>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#import torch.optim as optim\n",
    "\n",
    "\n",
    "#def train_mnist(config):\n",
    "    \n",
    " #   model = Network(nb_features=X_train.shape[1])\n",
    "  #  optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "   # for i in range(10):\n",
    "    #    training(batch_size=50, nb_steps_loss_sum=nb_steps_loss_sum)\n",
    "     #   acc = computeScore(X_train, y_train)\n",
    "      #  tune.report(mean_accuracy=acc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.5/15.9 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 5.000: None\nBracket: \nBracket: <br>Resources requested: 1/16 CPUs, 0/0 GPUs, 0.0/4.0 GiB heap, 0.0/1.37 GiB objects<br>Result logdir: C:\\Users\\Pierre\\ray_results\\training_2021-03-04_14-00-46<br>Number of trials: 1/8 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th>activation_function  </th><th style=\"text-align: right;\">  batch_size</th><th>criterion  </th><th style=\"text-align: right;\">  epoch</th><th>last_layer_activation  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  nb_hidden_neurons</th></tr>\n</thead>\n<tbody>\n<tr><td>training_a29bf_00000</td><td>RUNNING </td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     40</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">                 10</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for training_a29bf_00001:\n",
      "  date: 2021-03-04_14-00-47\n",
      "  done: false\n",
      "  experiment_id: c68a37fd34a54dcfa9ecf1f4f12896ad\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1286730915307999\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 20720\n",
      "  time_since_restore: 0.45407843589782715\n",
      "  time_this_iter_s: 0.45407843589782715\n",
      "  time_total_s: 0.45407843589782715\n",
      "  timestamp: 1614862847\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00001\n",
      "  \n",
      "Result for training_a29bf_00000:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: d90f3d7c7483439987eaf0f9e8f5fea1\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1448395252227783\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 13716\n",
      "  time_since_restore: 0.4775841236114502\n",
      "  time_this_iter_s: 0.4775841236114502\n",
      "  time_total_s: 0.4775841236114502\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00000\n",
      "  \n",
      "Result for training_a29bf_00002:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: 390d7eeb5c624861b1fbb730a536dd21\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1491467580199242\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 12216\n",
      "  time_since_restore: 0.45657968521118164\n",
      "  time_this_iter_s: 0.45657968521118164\n",
      "  time_total_s: 0.45657968521118164\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00002\n",
      "  \n",
      "Result for training_a29bf_00003:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: ed5c6267edee451584e64f3777acced3\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1862822398543358\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 8776\n",
      "  time_since_restore: 0.46958112716674805\n",
      "  time_this_iter_s: 0.46958112716674805\n",
      "  time_total_s: 0.46958112716674805\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00003\n",
      "  \n",
      "Result for training_a29bf_00004:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: 1b570093ddfe4776a017aa89b1e0deae\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.015159711241722\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 24416\n",
      "  time_since_restore: 0.4900858402252197\n",
      "  time_this_iter_s: 0.4900858402252197\n",
      "  time_total_s: 0.4900858402252197\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00004\n",
      "  \n",
      "Result for training_a29bf_00005:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: 0baa25628a4543c1b67fd7c75b138e08\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0131457224488258\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 14104\n",
      "  time_since_restore: 0.4900851249694824\n",
      "  time_this_iter_s: 0.4900851249694824\n",
      "  time_total_s: 0.4900851249694824\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00005\n",
      "  \n",
      "Result for training_a29bf_00006:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: 5dcd929ccb89484090ef025af41a7ab3\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.139014095067978\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 23064\n",
      "  time_since_restore: 0.4840846061706543\n",
      "  time_this_iter_s: 0.4840846061706543\n",
      "  time_total_s: 0.4840846061706543\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00006\n",
      "  \n",
      "Result for training_a29bf_00007:\n",
      "  date: 2021-03-04_14-00-48\n",
      "  done: false\n",
      "  experiment_id: 7104a0b68891459bae36804991379a6d\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1666033789515495\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 9736\n",
      "  time_since_restore: 0.48958587646484375\n",
      "  time_this_iter_s: 0.48958587646484375\n",
      "  time_total_s: 0.48958587646484375\n",
      "  timestamp: 1614862848\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a29bf_00007\n",
      "  \n",
      "2021-03-04 14:00:49,265\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,296\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,331\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,406\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "Result for training_a29bf_00001:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: c68a37fd34a54dcfa9ecf1f4f12896ad\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.932676263153553\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 20720\n",
      "  time_since_restore: 1.7182981967926025\n",
      "  time_this_iter_s: 0.3185546398162842\n",
      "  time_total_s: 1.7182981967926025\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00001\n",
      "  \n",
      "Result for training_a29bf_00002:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: 390d7eeb5c624861b1fbb730a536dd21\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 1.0280015915632248\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 12216\n",
      "  time_since_restore: 1.697295904159546\n",
      "  time_this_iter_s: 0.30805468559265137\n",
      "  time_total_s: 1.697295904159546\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00002\n",
      "  \n",
      "Result for training_a29bf_00000:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: d90f3d7c7483439987eaf0f9e8f5fea1\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.902913011610508\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 13716\n",
      "  time_since_restore: 1.759805679321289\n",
      "  time_this_iter_s: 0.31905531883239746\n",
      "  time_total_s: 1.759805679321289\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00000\n",
      "  \n",
      "Result for training_a29bf_00003:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: ed5c6267edee451584e64f3777acced3\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 1.0915901139378548\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 8776\n",
      "  time_since_restore: 1.7583045959472656\n",
      "  time_this_iter_s: 0.3020515441894531\n",
      "  time_total_s: 1.7583045959472656\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00003\n",
      "  \n",
      "Result for training_a29bf_00004:\n",
      "2021-03-04 14:00:49,454\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,480\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,543\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,554\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation_function': SiLU(), 'criterion': MSELoss(), 'last_layer_activation': Softmax(dim=None)}\n",
      "2021-03-04 14:00:49,586\tWARNING tune.py:429 -- Trial Runner checkpointing failed: [WinError 183] Impossible de crer un fichier dj existant: 'C:\\\\Users\\\\Pierre\\\\ray_results\\\\training_2021-03-04_14-00-46\\\\.tmp_generator' -> 'C:\\\\Users\\\\Pierre\\\\ray_results\\\\training_2021-03-04_14-00-46\\\\basic-variant-state-2021-03-04_14-00-46.json'\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: 1b570093ddfe4776a017aa89b1e0deae\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.7992387562990189\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 24416\n",
      "  time_since_restore: 1.7853105068206787\n",
      "  time_this_iter_s: 0.31505537033081055\n",
      "  time_total_s: 1.7853105068206787\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00004\n",
      "  \n",
      "Result for training_a29bf_00005:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: 0baa25628a4543c1b67fd7c75b138e08\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.8216670379042625\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 14104\n",
      "  time_since_restore: 1.7868103981018066\n",
      "  time_this_iter_s: 0.31905579566955566\n",
      "  time_total_s: 1.7868103981018066\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00005\n",
      "  \n",
      "Result for training_a29bf_00006:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: 5dcd929ccb89484090ef025af41a7ab3\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.9296447336673737\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 23064\n",
      "  time_since_restore: 1.8413200378417969\n",
      "  time_this_iter_s: 0.3640623092651367\n",
      "  time_total_s: 1.8413200378417969\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00006\n",
      "  \n",
      "Result for training_a29bf_00007:\n",
      "  date: 2021-03-04_14-00-49\n",
      "  done: true\n",
      "  experiment_id: 7104a0b68891459bae36804991379a6d\n",
      "  hostname: DESKTOP-7AOOQS1\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.9263295382261276\n",
      "  node_ip: 192.168.1.34\n",
      "  pid: 9736\n",
      "  time_since_restore: 1.8508219718933105\n",
      "  time_this_iter_s: 0.3330566883087158\n",
      "  time_total_s: 1.8508219718933105\n",
      "  timestamp: 1614862849\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: a29bf_00007\n",
      "  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.2/15.9 GiB<br>Using AsyncHyperBand: num_stopped=8\nBracket: Iter 5.000: None\nBracket: \nBracket: <br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.0 GiB heap, 0.0/1.37 GiB objects<br>Result logdir: C:\\Users\\Pierre\\ray_results\\training_2021-03-04_14-00-46<br>Number of trials: 8/8 (8 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name          </th><th>status    </th><th>loc  </th><th>activation_function  </th><th style=\"text-align: right;\">  batch_size</th><th>criterion  </th><th style=\"text-align: right;\">  epoch</th><th>last_layer_activation  </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_hidden_neurons</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n</thead>\n<tbody>\n<tr><td>training_a29bf_00000</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     40</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.75981</td><td style=\"text-align: right;\">0.902913</td></tr>\n<tr><td>training_a29bf_00001</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     50</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.7183 </td><td style=\"text-align: right;\">0.932676</td></tr>\n<tr><td>training_a29bf_00002</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     40</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.6973 </td><td style=\"text-align: right;\">1.028   </td></tr>\n<tr><td>training_a29bf_00003</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     50</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.7583 </td><td style=\"text-align: right;\">1.09159 </td></tr>\n<tr><td>training_a29bf_00004</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     40</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.78531</td><td style=\"text-align: right;\">0.799239</td></tr>\n<tr><td>training_a29bf_00005</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     50</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.78681</td><td style=\"text-align: right;\">0.821667</td></tr>\n<tr><td>training_a29bf_00006</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     40</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.84132</td><td style=\"text-align: right;\">0.929645</td></tr>\n<tr><td>training_a29bf_00007</td><td>TERMINATED</td><td>     </td><td>SiLU()               </td><td style=\"text-align: right;\">          50</td><td>MSELoss()  </td><td style=\"text-align: right;\">     50</td><td>Softmax(dim=None)      </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1.85082</td><td style=\"text-align: right;\">0.92633 </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-04 14:00:49,590\tINFO tune.py:450 -- Total run time: 3.37 seconds (3.33 seconds for the tuning loop).\n",
      "2021-03-04 14:00:49,672\tWARNING experiment_analysis.py:576 -- Could not find best trial. Did you pass the correct `metric` parameter?\n",
      "Best config:  None\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        reduction_factor=2,\n",
    "        max_t=5,\n",
    "        grace_period=5,\n",
    "        brackets=3)\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.01,0.001]),\n",
    "    #\"momentum\": tune.uniform(0.1, 0.9),\n",
    "    \"batch_size\": tune.grid_search([50]),\n",
    "    #\"optimizer\": tune.grid_search(['Adam']),\n",
    "    \"epoch\": tune.grid_search([40,50]),\n",
    "    \"nb_hidden_neurons\": tune.grid_search([10,20]),\n",
    "    \"activation_function\": tune.grid_search([nn.SiLU()]),\n",
    "    \"last_layer_activation\": tune.grid_search([nn.Softmax()]),\n",
    "    \"criterion\": tune.grid_search([nn.MSELoss()]),\n",
    "}\n",
    "\n",
    "analysis = tune.run(training, config=search_space,scheduler=scheduler)\n",
    "print(\"Best config: \", analysis.get_best_config(metric=\"loss\",mode=\"min\"))\n",
    "\n",
    "# Get a dataframe for analyzing trial results.\n",
    "test = analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    #\"momentum\": tune.uniform(0.1, 0.9),\n",
    "    \"batch_size\": tune.grid_search([10, 20, 30,40,50,60,70,80,90,100]),\n",
    "    \"optimizer\": tune.grid_search(['Adam','SGD','Adagrad','RMSprop']),\n",
    "    \"epoch\": tune.grid_search([10, 20, 30,40,50,60,70,80,90,100])\n",
    "    \"nb_hidden_neurons\": tune.grid_search([10, 20, 30,40,50,60,70,80,90,100])\n",
    "    \"nb_layer\": tune.grid_search([3,4,5,6]),\n",
    "    \"activation_function\": tune.grid_search(['Relu','SiLU']),\n",
    "    \"last_layer_activation\": tune.grid_search([nn.Softmax(),nn.Softmin(),nn.LogSoftmax()]),\n",
    "    \"criterion\": tune.grid_search([nn.MSELoss(),nn.L1Loss(),nn.CrossEntropyLoss()]),\n",
    "}"
   ]
  }
 ]
}